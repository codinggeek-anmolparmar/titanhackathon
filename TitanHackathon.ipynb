{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import clone\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('health_metrics.csv')\n",
        "\n",
        "# Remove any rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate the features (health metrics) from the target variable (fitness score)\n",
        "X = df.drop('fitness_score', axis=1)\n",
        "y = df['fitness_score']\n",
        "\n",
        "# Normalize the features using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform outlier detection and removal\n",
        "outlier_indices = detect_and_remove_outliers(X_scaled, y)\n",
        "X_scaled = np.delete(X_scaled, outlier_indices, axis=0)\n",
        "y = np.delete(y, outlier_indices, axis=0)\n",
        "\n",
        "# Perform feature extraction using PCA\n",
        "pca = PCA(n_components=5)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the base models for stacking\n",
        "base_models = [\n",
        "    DecisionTreeRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    GradientBoostingRegressor()\n",
        "]\n",
        "\n",
        "# Train the base models and generate stacked features\n",
        "stacked_features_train = np.zeros((X_train.shape[0], len(base_models)))\n",
        "stacked_features_test = np.zeros((X_test.shape[0], len(base_models)))\n",
        "\n",
        "for i, model in enumerate(base_models):\n",
        "    model.fit(X_train, y_train)\n",
        "    stacked_features_train[:, i] = model.predict(X_train)\n",
        "    stacked_features_test[:, i] = model.predict(X_test)\n",
        "\n",
        "# Define the meta model for stacking\n",
        "meta_model = MLPRegressor()\n",
        "\n",
        "# Train the meta model on stacked features\n",
        "meta_model.fit(stacked_features_train, y_train)\n",
        "\n",
        "# Make predictions using the meta model on stacked features\n",
        "meta_predictions = meta_model.predict(stacked_features_test)\n",
        "\n",
        "# Evaluate the meta model's performance\n",
        "meta_mse = mean_squared_error(y_test, meta_predictions)\n",
        "meta_r2 = r2_score(y_test, meta_predictions)\n",
        "\n",
        "print(\"\\nMeta Model:\")\n",
        "print(\"Mean Squared Error:\", meta_mse)\n",
        "print(\"R-squared Score:\", meta_r2)\n",
        "\n",
        "# Define the models for ensembling\n",
        "models = [\n",
        "    ('Decision Tree', DecisionTreeRegressor()),\n",
        "    ('Random Forest', RandomForestRegressor()),\n",
        "    ('Gradient Boosting', GradientBoostingRegressor()),\n",
        "    ('Neural Network', MLPRegressor())\n",
        "]\n",
        "\n",
        "# Create a stacking ensemble with multiple layers\n",
        "stacking_ensemble = StackingEnsemble(models)\n",
        "\n",
        "# Train the stacking ensemble\n",
        "stacking_ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the stacking ensemble\n",
        "ensemble_predictions = stacking_ensemble.predict(X_test)\n",
        "\n",
        "# Evaluate the ensemble model's performance\n",
        "ensemble_mse = mean_squared_error(y_test, ensemble_predictions)\n",
        "ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
        "\n",
        "print(\"\\nEnsemble Model:\")\n",
        "print(\"Mean Squared Error:\", ensemble_mse)\n",
        "print(\"R-squared Score:\", ensemble_r2)\n"
      ],
      "metadata": {
        "id": "X2N3u39fLoLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}